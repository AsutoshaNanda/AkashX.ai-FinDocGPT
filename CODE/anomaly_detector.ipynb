{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3ba48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading Financial Anomaly Detection models...\n",
      "✅ Financial Anomaly Detection initialized for Streamlit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple\n",
    "import logging\n",
    "\n",
    "\n",
    "class FinancialAnomalyDetector:\n",
    "    \"\"\"Advanced anomaly detection for financial metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self, contamination: float = 0.1):\n",
    "        self.contamination = contamination\n",
    "        self.isolation_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def detect_statistical_anomalies(self, data: pd.DataFrame, \n",
    "                                   columns: List[str] = None,\n",
    "                                   z_threshold: float = 3.0) -> Dict:\n",
    "        \"\"\"Detect anomalies using Z-score method.\"\"\"\n",
    "        if columns is None:\n",
    "            columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        anomalies = {}\n",
    "        \n",
    "        for column in columns:\n",
    "            if column not in data.columns:\n",
    "                continue\n",
    "                \n",
    "            values = data[column].dropna()\n",
    "            if len(values) < 3:  # Need minimum data points\n",
    "                continue\n",
    "            \n",
    "            # Calculate Z-scores\n",
    "            z_scores = np.abs(stats.zscore(values))\n",
    "            anomaly_indices = np.where(z_scores > z_threshold)[0]\n",
    "            \n",
    "            anomalies[column] = {\n",
    "                'anomaly_indices': anomaly_indices.tolist(),\n",
    "                'anomaly_values': values.iloc[anomaly_indices].tolist(),\n",
    "                'z_scores': z_scores[anomaly_indices].tolist(),\n",
    "                'mean': float(values.mean()),\n",
    "                'std': float(values.std()),\n",
    "                'threshold': z_threshold\n",
    "            }\n",
    "        \n",
    "        return anomalies\n",
    "    \n",
    "    def detect_isolation_forest_anomalies(self, data: pd.DataFrame, \n",
    "                                        columns: List[str] = None) -> Dict:\n",
    "        \"\"\"Detect anomalies using Isolation Forest.\"\"\"\n",
    "        if columns is None:\n",
    "            columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        # Prepare data\n",
    "        X = data[columns].dropna()\n",
    "        if len(X) < 5:  # Need minimum data points\n",
    "            return {'error': 'Insufficient data for anomaly detection'}\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Fit and predict\n",
    "        anomaly_labels = self.isolation_forest.fit_predict(X_scaled)\n",
    "        anomaly_scores = self.isolation_forest.score_samples(X_scaled)\n",
    "        \n",
    "        # Find anomalies (labeled as -1)\n",
    "        anomaly_mask = anomaly_labels == -1\n",
    "        anomaly_indices = np.where(anomaly_mask)[0]\n",
    "        \n",
    "        return {\n",
    "            'anomaly_indices': anomaly_indices.tolist(),\n",
    "            'anomaly_scores': anomaly_scores[anomaly_mask].tolist(),\n",
    "            'total_anomalies': int(np.sum(anomaly_mask)),\n",
    "            'anomaly_ratio': float(np.mean(anomaly_mask)),\n",
    "            'features_used': columns,\n",
    "            'contamination': self.contamination\n",
    "        }\n",
    "    \n",
    "    def detect_financial_metric_anomalies(self, financial_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Detect anomalies in specific financial metrics.\"\"\"\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(financial_data)\n",
    "        \n",
    "        financial_columns = ['revenue', 'profit', 'eps', 'cash_flow', 'debt', 'assets']\n",
    "        available_columns = [col for col in financial_columns if col in df.columns]\n",
    "        \n",
    "        if not available_columns:\n",
    "            return {'error': 'No financial metrics found for anomaly detection'}\n",
    "        \n",
    "        # Statistical anomalies\n",
    "        statistical_anomalies = self.detect_statistical_anomalies(df, available_columns)\n",
    "        \n",
    "        # Isolation Forest anomalies\n",
    "        isolation_anomalies = self.detect_isolation_forest_anomalies(df, available_columns)\n",
    "        \n",
    "        # Growth rate anomalies\n",
    "        growth_anomalies = self._detect_growth_anomalies(df, available_columns)\n",
    "        \n",
    "        return {\n",
    "            'statistical_anomalies': statistical_anomalies,\n",
    "            'isolation_forest_anomalies': isolation_anomalies,\n",
    "            'growth_rate_anomalies': growth_anomalies,\n",
    "            'summary': self._create_anomaly_summary(statistical_anomalies, isolation_anomalies, growth_anomalies)\n",
    "        }\n",
    "    \n",
    "    def _detect_growth_anomalies(self, data: pd.DataFrame, columns: List[str], \n",
    "                                threshold: float = 2.0) -> Dict:\n",
    "        \"\"\"Detect anomalies in growth rates.\"\"\"\n",
    "        growth_anomalies = {}\n",
    "        \n",
    "        for column in columns:\n",
    "            if column not in data.columns:\n",
    "                continue\n",
    "                \n",
    "            values = data[column].dropna()\n",
    "            if len(values) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Calculate period-over-period growth rates\n",
    "            growth_rates = values.pct_change().dropna()\n",
    "            \n",
    "            if len(growth_rates) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Find anomalous growth rates\n",
    "            growth_z_scores = np.abs(stats.zscore(growth_rates))\n",
    "            anomaly_mask = growth_z_scores > threshold\n",
    "            \n",
    "            if np.any(anomaly_mask):\n",
    "                anomaly_indices = np.where(anomaly_mask)[0]\n",
    "                growth_anomalies[f'{column}_growth'] = {\n",
    "                    'anomaly_indices': anomaly_indices.tolist(),\n",
    "                    'anomaly_growth_rates': growth_rates.iloc[anomaly_indices].tolist(),\n",
    "                    'z_scores': growth_z_scores[anomaly_mask].tolist(),\n",
    "                    'mean_growth_rate': float(growth_rates.mean()),\n",
    "                    'std_growth_rate': float(growth_rates.std())\n",
    "                }\n",
    "        \n",
    "        return growth_anomalies\n",
    "    \n",
    "    def _create_anomaly_summary(self, statistical: Dict, isolation: Dict, growth: Dict) -> Dict:\n",
    "        \"\"\"Create a summary of all detected anomalies.\"\"\"\n",
    "        total_statistical = sum(len(v.get('anomaly_indices', [])) for v in statistical.values())\n",
    "        total_isolation = isolation.get('total_anomalies', 0)\n",
    "        total_growth = sum(len(v.get('anomaly_indices', [])) for v in growth.values())\n",
    "        \n",
    "        return {\n",
    "            'total_statistical_anomalies': total_statistical,\n",
    "            'total_isolation_anomalies': total_isolation,\n",
    "            'total_growth_anomalies': total_growth,\n",
    "            'overall_anomaly_score': (total_statistical + total_isolation + total_growth) / 3,\n",
    "            'high_priority_metrics': self._identify_high_priority_anomalies(statistical, growth)\n",
    "        }\n",
    "    \n",
    "    def _identify_high_priority_anomalies(self, statistical: Dict, growth: Dict) -> List[str]:\n",
    "        \"\"\"Identify metrics with severe anomalies.\"\"\"\n",
    "        high_priority = []\n",
    "        \n",
    "        # Check statistical anomalies\n",
    "        for metric, data in statistical.items():\n",
    "            if len(data.get('anomaly_indices', [])) > 0:\n",
    "                max_z_score = max(data.get('z_scores', [0]))\n",
    "                if max_z_score > 4.0:  # Very high Z-score\n",
    "                    high_priority.append(f\"{metric} (extreme statistical deviation)\")\n",
    "        \n",
    "        # Check growth anomalies\n",
    "        for metric, data in growth.items():\n",
    "            if len(data.get('anomaly_indices', [])) > 0:\n",
    "                max_z_score = max(data.get('z_scores', [0]))\n",
    "                if max_z_score > 3.0:  # High growth anomaly\n",
    "                    high_priority.append(f\"{metric} (unusual growth pattern)\")\n",
    "        \n",
    "        return high_priority\n",
    "\n",
    "\n",
    "class StreamlitAnomalyDetector:\n",
    "    def __init__(self):\n",
    "        self.anomaly_detector = FinancialAnomalyDetector()  # Fixed class name\n",
    "        \n",
    "    def detect_for_streamlit(self, financial_data):\n",
    "        try:\n",
    "            # Use the correct method name from FinancialAnomalyDetector\n",
    "            result = self.anomaly_detector.detect_financial_metric_anomalies(financial_data)\n",
    "            \n",
    "            # Handle error case\n",
    "            if 'error' in result:\n",
    "                return {\n",
    "                    \"anomalies_detected\": [],\n",
    "                    \"anomaly_score\": 0.0,\n",
    "                    \"risk_level\": \"Unknown\",\n",
    "                    \"status\": \"error\",\n",
    "                    \"error\": result['error']\n",
    "                }\n",
    "            \n",
    "            # Extract summary data\n",
    "            summary = result.get('summary', {})\n",
    "            anomaly_score = summary.get('overall_anomaly_score', 0.0) / 10.0  # Normalize to 0-1\n",
    "            \n",
    "            # Format anomalies for Streamlit display\n",
    "            anomalies_detected = []\n",
    "            \n",
    "            # Add statistical anomalies\n",
    "            for metric, data in result.get('statistical_anomalies', {}).items():\n",
    "                if len(data.get('anomaly_indices', [])) > 0:\n",
    "                    anomalies_detected.append({\n",
    "                        'type': 'Statistical',\n",
    "                        'metric': metric,\n",
    "                        'count': len(data['anomaly_indices']),\n",
    "                        'severity': 'High' if max(data.get('z_scores', [0])) > 4.0 else 'Medium'\n",
    "                    })\n",
    "            \n",
    "            # Add isolation forest anomalies\n",
    "            isolation_data = result.get('isolation_forest_anomalies', {})\n",
    "            if isolation_data.get('total_anomalies', 0) > 0:\n",
    "                anomalies_detected.append({\n",
    "                    'type': 'Isolation Forest',\n",
    "                    'metric': 'Multiple features',\n",
    "                    'count': isolation_data['total_anomalies'],\n",
    "                    'severity': 'High' if isolation_data.get('anomaly_ratio', 0) > 0.2 else 'Medium'\n",
    "                })\n",
    "            \n",
    "            # Add growth anomalies\n",
    "            for metric, data in result.get('growth_rate_anomalies', {}).items():\n",
    "                if len(data.get('anomaly_indices', [])) > 0:\n",
    "                    anomalies_detected.append({\n",
    "                        'type': 'Growth Rate',\n",
    "                        'metric': metric,\n",
    "                        'count': len(data['anomaly_indices']),\n",
    "                        'severity': 'High' if max(data.get('z_scores', [0])) > 3.0 else 'Medium'\n",
    "                    })\n",
    "            \n",
    "            # Determine risk level\n",
    "            if anomaly_score > 0.7:\n",
    "                risk_level = \"High\"\n",
    "            elif anomaly_score > 0.3:\n",
    "                risk_level = \"Medium\"\n",
    "            else:\n",
    "                risk_level = \"Low\"\n",
    "                \n",
    "            return {\n",
    "                \"anomalies_detected\": anomalies_detected,\n",
    "                \"anomaly_score\": float(anomaly_score),\n",
    "                \"risk_level\": risk_level,\n",
    "                \"status\": \"success\",\n",
    "                \"total_anomalies\": summary.get('total_statistical_anomalies', 0) + \n",
    "                                 summary.get('total_isolation_anomalies', 0) + \n",
    "                                 summary.get('total_growth_anomalies', 0),\n",
    "                \"high_priority_metrics\": summary.get('high_priority_metrics', []),\n",
    "                \"detailed_results\": result  # Include full results for detailed analysis\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"anomalies_detected\": [],\n",
    "                \"anomaly_score\": 0.0,\n",
    "                \"risk_level\": \"Unknown\",\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "\n",
    "# Initialize the anomaly detector\n",
    "print(\"🔍 Loading Financial Anomaly Detection models...\")\n",
    "streamlit_anomaly = StreamlitAnomalyDetector()\n",
    "print(\"✅ Financial Anomaly Detection initialized for Streamlit\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
