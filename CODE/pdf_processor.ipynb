{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a82cc45-4ef8-45b3-918e-24dd7cee23e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF Processor ready for Streamlit integration\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import logging\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "class FinanceBenchProcessor:\n",
    "    \"\"\"Process FinanceBench PDFs and questions.\"\"\"\n",
    "    \n",
    "    def __init__(self, pdfs_dir: str, data_dir: str):\n",
    "        self.pdfs_dir = Path(pdfs_dir)\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Load the dataset\n",
    "        self.questions_df = pd.read_json(\n",
    "            self.data_dir / \"financebench_open_source.jsonl\", \n",
    "            lines=True\n",
    "        )\n",
    "        self.meta_df = pd.read_json(\n",
    "            self.data_dir / \"financebench_document_information.jsonl\", \n",
    "            lines=True\n",
    "        )\n",
    "        \n",
    "        # Merge questions with metadata\n",
    "        self.full_df = pd.merge(self.questions_df, self.meta_df, on=\"doc_name\")\n",
    "        \n",
    "    def extract_pdf_text(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract text from PDF using PyMuPDF.\"\"\"\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            text = \"\"\n",
    "            \n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc.load_page(page_num)\n",
    "                text += f\"\\n--- Page {page_num + 1} ---\\n\"\n",
    "                text += page.get_text()\n",
    "            \n",
    "            doc.close()\n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting PDF {pdf_path}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def load_all_documents(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Load all PDF documents and their metadata.\"\"\"\n",
    "        documents = {}\n",
    "        \n",
    "        for _, row in self.meta_df.iterrows():\n",
    "            doc_name = row['doc_name']\n",
    "            \n",
    "            # Find corresponding PDF file\n",
    "            pdf_files = list(self.pdfs_dir.glob(f\"{doc_name}*.pdf\"))\n",
    "            \n",
    "            if not pdf_files:\n",
    "                self.logger.warning(f\"PDF not found for {doc_name}\")\n",
    "                continue\n",
    "            \n",
    "            pdf_path = pdf_files[0]  # Take first match\n",
    "            self.logger.info(f\"Processing {pdf_path}\")\n",
    "            \n",
    "            # Extract text\n",
    "            text = self.extract_pdf_text(str(pdf_path))\n",
    "            \n",
    "            if text:\n",
    "                documents[doc_name] = {\n",
    "                    'doc_name': doc_name,\n",
    "                    'company': row['company'],\n",
    "                    'doc_type': row['doc_type'], \n",
    "                    'doc_period': row['doc_period'],\n",
    "                    'gics_sector': row['gics_sector'],\n",
    "                    'text': text,\n",
    "                    'pdf_path': str(pdf_path)\n",
    "                }\n",
    "        \n",
    "        self.logger.info(f\"Loaded {len(documents)} documents\")\n",
    "        return documents\n",
    "    \n",
    "    def get_questions_for_document(self, doc_name: str) -> List[Dict]:\n",
    "        \"\"\"Get all questions for a specific document.\"\"\"\n",
    "        doc_questions = self.full_df[self.full_df['doc_name'] == doc_name]\n",
    "        \n",
    "        questions = []\n",
    "        for _, row in doc_questions.iterrows():\n",
    "            questions.append({\n",
    "                'financebench_id': row['financebench_id'],\n",
    "                'question': row['question'],\n",
    "                'answer': row['answer'],\n",
    "                'question_type': row['question_type'],\n",
    "                'question_reasoning': row['question_reasoning'],\n",
    "                'company': row['company'],\n",
    "                'evidence': row['evidence'],\n",
    "                'justification': row['justification']\n",
    "            })\n",
    "        \n",
    "        return questions\n",
    "    \n",
    "    def get_all_questions(self) -> List[Dict]:\n",
    "        \"\"\"Get all questions from the dataset.\"\"\"\n",
    "        questions = []\n",
    "        \n",
    "        for _, row in self.questions_df.iterrows():\n",
    "            questions.append({\n",
    "                'financebench_id': row['financebench_id'],\n",
    "                'question': row['question'],\n",
    "                'answer': row['answer'],\n",
    "                'question_type': row['question_type'],\n",
    "                'question_reasoning': row['question_reasoning'],\n",
    "                'company': row['company'],\n",
    "                'doc_name': row['doc_name'],\n",
    "                'evidence': row['evidence'],\n",
    "                'justification': row['justification']\n",
    "            })\n",
    "        \n",
    "        return questions\n",
    "\n",
    "print(\"✅ PDF Processor ready for Streamlit integration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
